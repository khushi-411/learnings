{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a2fb618-51b8-4d9f-ac9a-a42276e5be78",
   "metadata": {},
   "source": [
    "### Reference: [Andrej Karpathy YouTube video Link](https://youtu.be/q8SA3rM6ckI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8396e44-e102-446d-b77f-292e69f94c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c5be6de-a942-4eb2-80d5-1f97b034f2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2527663a-7ab4-4dd0-ba2a-6cf1b96b7185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1fe78cb-904c-4326-8f9a-b4d7dafda503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02c036a3-76dc-44c6-8876-c92d8fcb3715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])      # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])  # 10%\n",
    "Xte, Yte = build_dataset(words[n2:])      # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8270edb6-4b8e-4a63-af9d-2a2c0536065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3787d128-9ff3-42f0-93c0-9152ac6a435c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "# MLP revisited\n",
    "n_embd = 10  # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64  # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)  # for reproducibility\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/(n_embd * block_size)**0.5\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1  # it's useless, just using it here\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "\n",
    "# BatchNorm parameters\n",
    "# check initialization is different from before\n",
    "# because if we just use zero, it could mask incorrect implementation of the backward pass\n",
    "# by making it a small number; we are trying to unmask it\n",
    "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
    "\n",
    "bnmean_running = torch.zeros((1, n_hidden))\n",
    "bnstd_running = torch.ones((1, n_hidden))\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))  # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "619e4f54-cafb-4fd5-8ba3-d18dc1910343",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size\n",
    "# constructs a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]  # batch X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "494ad9e2-7c98-44b7-9e84-667eb766c24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khushi/anaconda3/envs/dev/lib/python3.10/site-packages/torch/autograd/graph.py:690: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.3174, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunked\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb]  # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1)  # concatenate the vectors\n",
    "\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1  # hidden layer pre-activation\n",
    "\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True)  # Bessel's correction\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact)  # hidden layer\n",
    "\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2  # output layer\n",
    "\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logits_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logits_maxes  # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1  # if we use (1.0 / counts_sum) instead then I can't get exact backdrop\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv,\n",
    "          norm_logits, logits_maxes, logits, h, hpreact, bnraw,\n",
    "          bnvar_inv, bnvar, bndiff2, bndiff, bnmeani, hprebn,\n",
    "          embcat, emb]:\n",
    "    t.retain_grad()\n",
    "\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7448fba8-5cc0-4fa9-95f9-8e86e6d7e9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04271661-bd6e-4036-9fdb-67521e2176b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64, 27]),\n",
       " torch.Size([27]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, h.shape, W2.shape, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af7aad21-87cd-441a-8e67-8cf583c2b4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([1, 64]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpreact.shape, bngain.shape, bnraw.shape, bnbias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "327b19d0-d1e1-4f4e-bdcf-527c52dff72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnraw.shape, bndiff.shape, bnvar_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfe0eec7-536e-4164-9e56-43927f603056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]), torch.Size([32, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnvar.shape, bndiff2.shape, hprebn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "704aa299-ef2e-4817-8df2-3a6624a773bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([32, 30]),\n",
       " torch.Size([30, 64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([32, 3, 10]),\n",
       " torch.Size([27, 10]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hprebn.shape, embcat.shape, W1.shape, b1.shape, emb.shape, C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40011bb2-9dec-4483-b5a4-d2792680fe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits_maxes    | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits_maxes    | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "bngain          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "bnbias          | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n",
      "bnraw           | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "bnvar_inv       | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "bnvar           | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n",
      "bndiff2         | exact: False | approximate: True  | maxdiff: 2.1827872842550278e-11\n",
      "bndiff          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "bnmeani         | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "hprebn          | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n",
      "embcat          | exact: False | approximate: False | maxdiff: 25.94855499267578\n",
      "W1              | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "b1              | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n",
      "emb             | exact: False | approximate: False | maxdiff: 25.94855499267578\n",
      "C               | exact: False | approximate: False | maxdiff: 310.36480712890625\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = (1.0 / probs) * dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogits_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogits_maxes\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = (1.0/(n-1)) * torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff += 2*bndiff * dbndiff2\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-torch.ones_like(bndiff) * dbndiff).sum(0)\n",
    "dhprebn += 1/n * torch.ones_like(hprebn) * dbnmeani\n",
    "dembcat = hprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "demb = dembcat.view(emb.shape)\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k, j]\n",
    "        dC[ix] += demb[k, j]\n",
    "\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logits_maxes', dlogits_maxes, logits_maxes)\n",
    "cmp('logits_maxes', dlogits_maxes, logits_maxes)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75548777-465f-457a-bbaa-40ec5815b5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.317436456680298 diff: 2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge, look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "164ec39c-df21-4229-9b96-e9afc86e69f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 6.05359673500061e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits /= n\n",
    "\n",
    "cmp('logits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddea9c4b-b697-40b2-a35c-68af0081bf74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ceb01f7-08ad-400d-b43b-b8a441d49227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0729, 0.0844, 0.0171, 0.0505, 0.0196, 0.0856, 0.0229, 0.0380, 0.0200,\n",
       "        0.0313, 0.0355, 0.0366, 0.0366, 0.0262, 0.0343, 0.0133, 0.0087, 0.0190,\n",
       "        0.0171, 0.0586, 0.0498, 0.0215, 0.0244, 0.0699, 0.0608, 0.0259, 0.0194],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc8bce2f-e554-47f7-8bea-c0c6612d3e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0729,  0.0844,  0.0171,  0.0505,  0.0196,  0.0856,  0.0229,  0.0380,\n",
       "        -0.9800,  0.0313,  0.0355,  0.0366,  0.0366,  0.0262,  0.0343,  0.0133,\n",
       "         0.0087,  0.0190,  0.0171,  0.0586,  0.0498,  0.0215,  0.0244,  0.0699,\n",
       "         0.0608,  0.0259,  0.0194], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "921fe21e-4a42-4751-b8cf-71bc3fc81dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8626e-09, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9885d432-558d-467c-93b3-6731849bfbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe6072d2f50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "167df33b-7bc1-4e32-9de8-c8dde476c0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge, look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36611c9f-0121-4d1e-83b2-a7ca857fcf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn)  # we can only get approximate to be true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "feb40741-ec10-4cb6-9c22-782b9a527de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhprebn.shape, bngain.shape, bnvar_inv.shape, dbnraw.shape, dbnraw.sum(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1046b0f4-1030-46f5-b975-f7cab781dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "050933e1-afca-430f-9e76-3d022e1247f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10  # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200  # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))  # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c58bbffa-448b-4d52-b58a-16998be9f345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.7921\n",
      "  10000/ 200000: 2.1501\n",
      "  20000/ 200000: 2.3785\n",
      "  30000/ 200000: 2.4510\n",
      "  40000/ 200000: 2.0181\n",
      "  50000/ 200000: 2.4085\n",
      "  60000/ 200000: 2.4159\n",
      "  70000/ 200000: 2.1294\n",
      "  80000/ 200000: 2.3293\n",
      "  90000/ 200000: 2.0856\n",
      " 100000/ 200000: 1.9439\n",
      " 110000/ 200000: 2.3950\n",
      " 120000/ 200000: 1.9052\n",
      " 130000/ 200000: 2.5249\n",
      " 140000/ 200000: 2.3373\n",
      " 150000/ 200000: 2.1670\n",
      " 160000/ 200000: 1.9862\n",
      " 170000/ 200000: 1.8059\n",
      " 180000/ 200000: 1.9529\n",
      " 190000/ 200000: 1.9449\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size\n",
    "lossi = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    # kick off optimization\n",
    "    for i in range(max_steps):\n",
    "\n",
    "        # minibatch construct\n",
    "        ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "        Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "        # forward pass\n",
    "        emb = C[Xb] # embed the characters into vectors\n",
    "        embcat = emb.view(emb.shape[0], -1)  # concatenate the vectors\n",
    "    \n",
    "        # Linear layer\n",
    "        hprebn = embcat @ W1 + b1  # hidden layer pre-activation\n",
    "        \n",
    "        # BatchNorm layer\n",
    "        bnmean = hprebn.mean(0, keepdim=True)\n",
    "        bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "        bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "        bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "        hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "        # Non-linearity\n",
    "        h = torch.tanh(hpreact)  # hidden layer\n",
    "        logits = h @ W2 + b2  # output layer\n",
    "        loss = F.cross_entropy(logits, Yb)  # loss function\n",
    "\n",
    "        # backward pass\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        # loss.backward()  # use this for correctness comparisons, delete it later!\n",
    "\n",
    "        # manual backprop!\n",
    "        dlogits = F.softmax(logits, 1)\n",
    "        dlogits[range(n), Yb] -= 1\n",
    "        dlogits /= n\n",
    "        # 2nd layer backprop\n",
    "        dh = dlogits @ W2.T\n",
    "        dW2 = h.T @ dlogits\n",
    "        db2 = dlogits.sum(0)\n",
    "        # tanh\n",
    "        dhpreact = (1.0 - h**2) * dh\n",
    "        # batchnorm backprop\n",
    "        dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "        dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "        dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "        # 1st layer\n",
    "        dembcat = dhprebn @ W1.T\n",
    "        dW1 = embcat.T @ dhprebn\n",
    "        db1 = dhprebn.sum(0)\n",
    "        # embedding\n",
    "        demb = dembcat.view(emb.shape)\n",
    "        dC = torch.zeros_like(C)\n",
    "    \n",
    "        for k in range(Xb.shape[0]):\n",
    "            for j in range(Xb.shape[1]):\n",
    "                ix = Xb[k,j]\n",
    "                dC[ix] += demb[k,j]\n",
    "        grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "\n",
    "        # update\n",
    "        lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "        for p, grad in zip(parameters, grads):\n",
    "            # p.data += -lr * p.grad\n",
    "            p.data += -lr * grad\n",
    "\n",
    "        # track stats\n",
    "        if i % 10000 == 0:  # print every once in a while\n",
    "            print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "        lossi.append(loss.log10().item())\n",
    "\n",
    "        # if i >= 100:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c463317e-276e-49ed-9e47-8827550297b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # pass the training set through\n",
    "    emb = C[Xtr]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    # measure the mean/std over the entire training set\n",
    "    bnmean = hpreact.mean(0, keepdim=True)\n",
    "    bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "547fb5d9-4e0c-4c27-894d-a133168cafa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.069486379623413\n",
      "val 2.1093454360961914\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def split_loss(split):\n",
    "    x,y = {\n",
    "        'train': (Xtr, Ytr),\n",
    "        'val': (Xdev, Ydev),\n",
    "        'test': (Xte, Yte),\n",
    "    }[split]\n",
    "    emb = C[x]  # (N, block_size, n_embd)\n",
    "    embcat = emb.view(emb.shape[0], -1)  # concat into (N, block_size * n_embd)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "    h = torch.tanh(hpreact)  # (N, n_hidden)\n",
    "    logits = h @ W2 + b2  # (N, vocab_size)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac33a3cb-aedd-45cd-8fdd-fee1329d2aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mora.\n",
      "mayah.\n",
      "see.\n",
      "madhayla.\n",
      "ren.\n",
      "ruchadrie.\n",
      "cadelynnelin.\n",
      "shi.\n",
      "jen.\n",
      "eden.\n",
      "sana.\n",
      "arleigh.\n",
      "malailin.\n",
      "shubergihirael.\n",
      "kindreelynn.\n",
      "novana.\n",
      "ubelled.\n",
      "ryyah.\n",
      "faeha.\n",
      "kayshayan.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size  # initialize with all ...\n",
    "    while True:\n",
    "        # forward pass:\n",
    "        # Embedding\n",
    "        emb = C[torch.tensor([context])]  # (1,block_size,d)      \n",
    "        embcat = emb.view(emb.shape[0], -1)  # concat into (N, block_size * n_embd)\n",
    "        hpreact = embcat @ W1 + b1\n",
    "        hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "        h = torch.tanh(hpreact)  # (N, n_hidden)\n",
    "        logits = h @ W2 + b2  # (N, vocab_size)\n",
    "        # Sample\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92cd78d-93ef-469d-a514-e9fd35a8a102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
